{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from box import Box\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
    "from fast_bert.data_cls import BertDataBunch, InputExample, InputFeatures, MultiLabelTextProcessor, convert_examples_to_features\n",
    "from fast_bert.learner_cls import BertLearner\n",
    "from fast_bert.metrics import accuracy_multilabel, accuracy_thresh, fbeta, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', -1)\n",
    "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/')\n",
    "LABEL_PATH = Path('./labels/')\n",
    "\n",
    "#AUG_DATA_PATH = Path('./data/data_augmentation/')\n",
    "\n",
    "MODEL_PATH=Path('./models/')\n",
    "LOG_PATH=Path('./logs/')\n",
    "MODEL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "model_state_dict = None\n",
    "#BERT_PRETRAINED_PATH = Path('./models/base_model')\n",
    "LOG_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_PATH = MODEL_PATH\n",
    "\n",
    "FINETUNED_PATH_BERT = OUTPUT_PATH/'bert_plain/model_out' \n",
    "FINETUNED_PATH_XLNET = OUTPUT_PATH/'xlnet/model_out'\n",
    "\n",
    "\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Box({\n",
    "    \"run_text\": \"multilabel toxic comments with freezable layers\",\n",
    "    \"train_size\": -1,\n",
    "    \"val_size\": -1,\n",
    "    \"log_path\": LOG_PATH,\n",
    "    \"full_data_dir\": DATA_PATH,\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"task_name\": \"toxic_classification_lib\",\n",
    "    \"no_cuda\": False,\n",
    "    \"bert_model\": None,\n",
    "    \"output_dir\": OUTPUT_PATH,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_train_epochs\": 6,\n",
    "    \"warmup_proportion\": 0.0,\n",
    "    \"no_cuda\": False,\n",
    "    \"local_rank\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimize_on_cpu\": False,\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"max_steps\": -1,\n",
    "    \"multi_gpu\": False,\n",
    "    \"warmup_steps\": 500,\n",
    "    \"logging_steps\": 50,\n",
    "    \"eval_all_checkpoints\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"overwrite_cache\": False,\n",
    "    \"seed\": 42,\n",
    "    \"loss_scale\": 128,\n",
    "    \"task_name\": 'intent',\n",
    "    \"model_name\": 'bert-base-cased',\n",
    "    \"model_type\": 'bert'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "logfile = str(LOG_PATH/'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(logfile),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_bert.prediction import BertClassificationPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(str(FINETUNED_PATH_BERT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2020 10:06:44 - INFO - transformers.configuration_utils -   loading configuration file models/bert_plain/model_out/config.json\n",
      "05/13/2020 10:06:44 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 6,\n",
      "  \"architectures\": [\n",
      "    \"BertForMultiLabelSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "05/13/2020 10:06:44 - INFO - transformers.tokenization_utils -   Model name 'models/bert_plain/model_out' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'models/bert_plain/model_out' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/13/2020 10:06:44 - INFO - transformers.tokenization_utils -   Didn't find file models/bert_plain/model_out/added_tokens.json. We won't load it.\n",
      "05/13/2020 10:06:44 - INFO - transformers.tokenization_utils -   loading file models/bert_plain/model_out/vocab.txt\n",
      "05/13/2020 10:06:44 - INFO - transformers.tokenization_utils -   loading file None\n",
      "05/13/2020 10:06:44 - INFO - transformers.tokenization_utils -   loading file models/bert_plain/model_out/special_tokens_map.json\n",
      "05/13/2020 10:06:44 - INFO - transformers.tokenization_utils -   loading file models/bert_plain/model_out/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(str(FINETUNED_PATH_BERT), use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2020 10:06:52 - INFO - root -   Loading features from cached file data/cache/cached_bert_train_multi_label_512_train.csv\n",
      "05/13/2020 10:07:02 - INFO - root -   Loading features from cached file data/cache/cached_bert_dev_multi_label_512_val.csv\n",
      "05/13/2020 10:07:06 - INFO - root -   Loading features from cached file data/cache/cached_bert_test_multi_label_512_test\n"
     ]
    }
   ],
   "source": [
    "databunch = BertDataBunch(args['data_dir'], LABEL_PATH, tokenizer=tokenizer, train_file='train.csv', val_file='val.csv',\n",
    "                          test_data='test.csv', label_file='labels.csv',\n",
    "                          text_col=\"comment_text\", label_col=label_cols,\n",
    "                          batch_size_per_gpu=args['train_batch_size'], max_seq_length=args['max_seq_length'], \n",
    "                          multi_gpu=args.multi_gpu, multi_label=True, model_type=args.model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2020 10:08:37 - INFO - transformers.configuration_utils -   loading configuration file models/bert_plain/model_out/config.json\n",
      "05/13/2020 10:08:37 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 6,\n",
      "  \"architectures\": [\n",
      "    \"BertForMultiLabelSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "05/13/2020 10:08:37 - INFO - transformers.modeling_utils -   loading weights file models/bert_plain/model_out/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "learner = BertLearner.from_pretrained_model(\n",
    "            databunch,\n",
    "            FINETUNED_PATH_BERT,\n",
    "            metrics=[],\n",
    "            device=device,\n",
    "            logger=None,\n",
    "            output_dir=None,\n",
    "            warmup_steps=0,\n",
    "            multi_gpu=False,\n",
    "            is_fp16=False,\n",
    "            multi_label=True,\n",
    "            logging_steps=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2020 10:08:44 - INFO - root -   Writing example 0 of 63978\n",
      "05/13/2020 10:08:46 - INFO - root -   Writing example 10000 of 63978\n",
      "05/13/2020 10:08:48 - INFO - root -   Writing example 20000 of 63978\n",
      "05/13/2020 10:08:51 - INFO - root -   Writing example 30000 of 63978\n",
      "05/13/2020 10:08:53 - INFO - root -   Writing example 40000 of 63978\n",
      "05/13/2020 10:08:56 - INFO - root -   Writing example 50000 of 63978\n",
      "05/13/2020 10:08:59 - INFO - root -   Writing example 60000 of 63978\n"
     ]
    }
   ],
   "source": [
    "output = learner.predict_batch(list(pd.read_csv(DATA_PATH/\"test.csv\")['comment_text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(output).to_csv(DATA_PATH/'output_bert.csv')\n",
    "#results = pd.read_csv(DATA_PATH/'output_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame([{item[0]: item[1] for item in pred} for pred in output])\n",
    "#preds.to_csv(DATA_PATH/'predictions_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>threat</th>\n",
       "      <th>severe_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.518612</td>\n",
       "      <td>0.023604</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.069452</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic    insult   obscene  identity_hate    threat  severe_toxic\n",
       "0  0.000597  0.000272  0.000248       0.000241  0.000175      0.000163\n",
       "1  0.518612  0.023604  0.007075       0.003877  0.000791      0.000709\n",
       "2  0.069452  0.002453  0.001782       0.000824  0.000218      0.000195\n",
       "3  0.000662  0.000281  0.000259       0.000230  0.000145      0.000157\n",
       "4  0.000555  0.000255  0.000246       0.000228  0.000167      0.000164"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATA_PATH/\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(test.iloc[:,3:])\n",
    "prediction = np.where(np.array(preds)>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_only_target = target[:,0]\n",
    "tox_only_prediction = prediction[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8465097377223421\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(target, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9158929632061021\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(tox_only_target, tox_only_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Box({\n",
    "    \"run_text\": \"multilabel toxic comments with freezable layers\",\n",
    "    \"train_size\": -1,\n",
    "    \"val_size\": -1,\n",
    "    \"log_path\": LOG_PATH,\n",
    "    \"full_data_dir\": DATA_PATH,\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"task_name\": \"toxic_classification_lib\",\n",
    "    \"no_cuda\": False,\n",
    "    \"bert_model\": None,\n",
    "    \"output_dir\": OUTPUT_PATH,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_train_epochs\": 6,\n",
    "    \"warmup_proportion\": 0.0,\n",
    "    \"no_cuda\": False,\n",
    "    \"local_rank\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimize_on_cpu\": False,\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"max_steps\": -1,\n",
    "    \"multi_gpu\": False,\n",
    "    \"warmup_steps\": 500,\n",
    "    \"logging_steps\": 50,\n",
    "    \"eval_all_checkpoints\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"overwrite_cache\": False,\n",
    "    \"seed\": 42,\n",
    "    \"loss_scale\": 128,\n",
    "    \"task_name\": 'intent',\n",
    "    \"model_name\": 'xlnet-base-cased',\n",
    "    \"model_type\": 'xlnet'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2020 10:25:50 - INFO - transformers.configuration_utils -   loading configuration file models/xlnet/model_out/config.json\n",
      "05/13/2020 10:25:50 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 6,\n",
      "  \"architectures\": [\n",
      "    \"BertForMultiLabelSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "05/13/2020 10:25:50 - INFO - transformers.tokenization_utils -   Model name 'models/xlnet/model_out' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'models/xlnet/model_out' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/13/2020 10:25:50 - INFO - transformers.tokenization_utils -   Didn't find file models/xlnet/model_out/added_tokens.json. We won't load it.\n",
      "05/13/2020 10:25:50 - INFO - transformers.tokenization_utils -   loading file models/xlnet/model_out/vocab.txt\n",
      "05/13/2020 10:25:50 - INFO - transformers.tokenization_utils -   loading file None\n",
      "05/13/2020 10:25:50 - INFO - transformers.tokenization_utils -   loading file models/xlnet/model_out/special_tokens_map.json\n",
      "05/13/2020 10:25:50 - INFO - transformers.tokenization_utils -   loading file models/xlnet/model_out/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(str(FINETUNED_PATH_XLNET), use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2020 10:26:07 - INFO - root -   Loading features from cached file data/cache/cached_bert_train_multi_label_512_train.csv\n",
      "05/13/2020 10:26:16 - INFO - root -   Loading features from cached file data/cache/cached_bert_dev_multi_label_512_val.csv\n",
      "05/13/2020 10:26:20 - INFO - root -   Loading features from cached file data/cache/cached_bert_test_multi_label_512_test\n"
     ]
    }
   ],
   "source": [
    "databunch = BertDataBunch(args['data_dir'], LABEL_PATH, tokenizer=tokenizer, train_file='train.csv', val_file='val.csv',\n",
    "                          test_data='test.csv', label_file='labels.csv',\n",
    "                          text_col=\"comment_text\", label_col=label_cols,\n",
    "                          batch_size_per_gpu=args['train_batch_size'], max_seq_length=args['max_seq_length'], \n",
    "                          multi_gpu=args.multi_gpu, multi_label=True, model_type=args.model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2020 10:26:43 - INFO - transformers.configuration_utils -   loading configuration file models/xlnet/model_out/config.json\n",
      "05/13/2020 10:26:43 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 6,\n",
      "  \"architectures\": [\n",
      "    \"BertForMultiLabelSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "05/13/2020 10:26:43 - INFO - transformers.modeling_utils -   loading weights file models/xlnet/model_out/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "learner = BertLearner.from_pretrained_model(\n",
    "            databunch,\n",
    "            FINETUNED_PATH_XLNET,\n",
    "            metrics=[],\n",
    "            device=device,\n",
    "            logger=None,\n",
    "            output_dir=None,\n",
    "            warmup_steps=0,\n",
    "            multi_gpu=False,\n",
    "            is_fp16=False,\n",
    "            multi_label=True,\n",
    "            logging_steps=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2020 10:26:57 - INFO - root -   Writing example 0 of 63978\n",
      "05/13/2020 10:26:59 - INFO - root -   Writing example 10000 of 63978\n",
      "05/13/2020 10:27:02 - INFO - root -   Writing example 20000 of 63978\n",
      "05/13/2020 10:27:04 - INFO - root -   Writing example 30000 of 63978\n",
      "05/13/2020 10:27:07 - INFO - root -   Writing example 40000 of 63978\n",
      "05/13/2020 10:27:10 - INFO - root -   Writing example 50000 of 63978\n",
      "05/13/2020 10:27:12 - INFO - root -   Writing example 60000 of 63978\n"
     ]
    }
   ],
   "source": [
    "output = learner.predict_batch(list(pd.read_csv(DATA_PATH/\"test.csv\")['comment_text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output).to_csv(DATA_PATH/'output_xlnet.csv')\n",
    "results = pd.read_csv(DATA_PATH/'output_xlnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame([{item[0]: item[1] for item in pred} for pred in output])\n",
    "preds.to_csv(DATA_PATH/'predictions_xlnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.where(np.array(preds)>0.5, 1, 0)\n",
    "tox_only_prediction = prediction[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8488074025446247\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(target, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916830785582544\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(tox_only_target, tox_only_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
